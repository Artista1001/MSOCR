from django.http.response import JsonResponse
import ast
import pytesseract
import os
import cv2
from cv2 import dnn_superres
import numpy as np
import imutils
from pathlib import Path
class OCRcls:
    
    def init_super(model, IMG, base_path):
    
        # Define global variable
        global sr, model_name, model_scale
        
        # Create an SR object
        sr = dnn_superres.DnnSuperResImpl_create()
        
        # Define model path
        model_path = os.path.join(base_path , model +".pb")
        
        # Extract model name from model path
        model_name = model.split('_')[0].lower()
        
        # Extract model scale from model path
        model_scale = int(model.split("_")[1][1])
            
        # Read the desired model
        sr.readModel(model_path)
        
        sr.setModel(model_name, model_scale)

        result = sr.upsample(IMG)

        return result
        
    def ocrfunction(reqimage, pixels, qryimage):
        print(qryimage)
        data_dict = {}
        #BASE_DIR = str(Path(__file__).resolve().parent.parent) + "\OCR\models"
        CWD = os.getcwd()
        BASE_DIR = str(CWD)+ "\Ocr_service\OCR\models"
        print(BASE_DIR)
        
        pytesseract.pytesseract.tesseract_cmd = "C:\\Users\\valanich\\AppData\\Local\\Tesseract-OCR\\tesseract.exe"
        # codes
        # codes
        reqimage = cv2.imread(reqimage,cv2.IMREAD_COLOR)
        
        h, w, c = reqimage.shape
        Roi = ast.literal_eval(pixels)
    
        #per = 25
        qryimg = cv2.imread(qryimage,cv2.IMREAD_COLOR)
        print(qryimg.shape)
        print(reqimage.shape)

        orb = cv2.ORB_create(5000)
        keypoints, descriptors = orb.detectAndCompute(qryimg, None)
        keypoints_2, descriptors_2 = orb.detectAndCompute(reqimage, None)
        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)
        matches = matcher.match(descriptors_2, descriptors)
        matches = sorted(matches, key = lambda x:x.distance) 
        # kp1, des1 = orb.detectAndCompute(reqimage, None)
        # #img = cv2.resize(img, (w // 2, h // 2))
        # #cv2.imshow(indexvalue, img)
        # kp2, des2 = orb.detectAndCompute(qryimg, None)
        # Bruteforce = cv2.BFMatcher(cv2.NORM_HAMMING)
        # matches = Bruteforce.match(des2, des1)
        # #matches.sort(kePIP uninstally= lambda x: x.distance)
        # matches = sorted(matches, key=lambda x: x.distance)
        # good = matches[:int(len(matches)*(per/100))]
        # imagMatch = cv2.drawMatches(qryimg, kp2, reqimage, kp1, good[:100], None, flags=2)
        # imagMatch = cv2.resize(imagMatch, (w, h))
        #cv2.imshow(indexvalue, imagMatch)
        best_matches = matches[:int(len(matches) * 0.25)] # 25% of the best matches
        # srcPoints = np.float32([kp2[m.queryIdx].pt for m in good]).reshape(1, -1, 2)
        # desPoints = np.float32([kp1[m.trainIdx].pt for m in good]).reshape(1, -1, 2)
        srcPoints = np.float32([keypoints_2[m.queryIdx].pt for m in best_matches]).reshape(-1, 1, 2)
        desPoints = np.float32([keypoints[m.trainIdx].pt for m in best_matches]).reshape(-1, 1, 2)

        M, _ = cv2.findHomography(srcPoints, desPoints, cv2.RANSAC,5.0)
        imgScan = cv2.warpPerspective(reqimage,M,(w,h))
        #imgScan = cv2.resize(imgScan, (w // 2, h // 2))
        #cv2.imshow(indexvalue, imgScan)

        imgShow = imgScan.copy()
        imagMask = np.zeros_like(imgShow)
        
        for countloop1, r in enumerate(Roi):
            # cv2.rectangle(imagMask, ((r[0][0]),r[0][1]), ((r[1][0]),r[1][1]), (0,255,0), cv2.FILLED)
            # imgShow = cv2.addWeighted(imgShow,0.99,imagMask,0.1,0)
            # imgShow = cv2.resize(imgShow, (w, h))
            #cv2.imshow("REQimg", imgShow)
            imgCrop = imgScan[r[0][1]:r[1][1], r[0][0]:r[1][0]]
            # Upscale the image
            #Final_Img = sr.upsample(imgCrop)
            # Get the width and height of the image
            height, width, _ = imgCrop.shape

            resixzecrop = cv2.resize(imgCrop, (width , height ))
            ##Improving quality by DNN3x
            #Final_Img = OCRcls.init_super("ESPCN_x4",resixzecrop, BASE_DIR)
            #imgresize  = imutils.resize(Final_Img,width=550)#515
        
            gray = cv2.cvtColor(resixzecrop, cv2.COLOR_BGR2GRAY)
        
            thresh = cv2.threshold(gray, 0, 255,
                cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
            #cv2.imshow("Otsu", thresh)
       
            dist = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)
        
            dist = cv2.normalize(dist, dist, 0, 1.0, cv2.NORM_MINMAX)
            dist = (dist * 255).astype("uint8")
            #cv2.imshow("Dist", dist)
            # threshold the distance transform using Otsu's method
            dist = cv2.threshold(dist, 0, 255,
                cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
            #cv2.imshow("Dist Otsu", dist)
           
            #cv2.imshow(str(countloop1),dist)
            outputdata= pytesseract.image_to_string(dist).strip()
            data_dict[r[2]]= outputdata.replace('\n', ' ').replace('  ', ' ')
            print(f'{r[2]}:{outputdata}'.strip())
        return data_dict
        # return JsonResponse(json.dumps({
        #     "RefImage": refimage,
        #     "Tupel": pixels,
        #     "image": Image
        # }), safe=False)

    